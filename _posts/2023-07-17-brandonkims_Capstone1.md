---
layout: single
title: "First post & Capstone Design Layout"
---

### 3월달에 시작된 캡스톤 디자인 프로젝트를 7월이 되고서야 포스팅을 시작한다.

졸음운전을 판단하는 시스템을 제작 하는 것을 목표로 한다.

눈의 종횡비(일명 EAR, Eye Aspect Ratio), 턱의 기울기, 눈썹의 움직임 등 다양한 요소가 있지만
우리팀은 *EAR에 따른 졸음운전을 판단*하는 것을 목표로 삼았다.

이것을 완성시키고 나서 추후 턱의 기울기나 다른 요소를 추가적으로 진행할 계획에 있다.

사실 우리 주제는 여러 Github 블로그 포스팅에서 많이 진행한 프로젝트이다.
그 중 가장 간단하고 정확했던 시스템은
실시간으로 눈의 종횡비를 측정하여 특정 threshold(EAR의 임계값)을 기반으로
해당 사용자의 졸음/정상 상태를 측정하는 것이었다.

*하지만*  우리는, ~~사서 고생하는 일이지만~~ 우리만의 고유한 Dataset(운전하는 영상)을 가지고 직접 augmentation 및 정제 작업을 거쳐 이를 졸음/정상 상태로 분류하고 ML/DL 을 거치는 프로젝트를 하고 싶었다.

왜?

그냥.

주변에서 있을 법한 event를 가지고 ML/DL 프로젝트를 진행할 기회가 흔치 않을 법했고, 사실 말로만 듣던 ML/DL을 직접 부딪히며 알아가보고 싶어서. 단지 그냥 이었다.

서론이 길었다.

프로젝트 과정은 다음과 같다.

1. Dataset(운전하는 영상)을 확보
2. 영상을 프레임단위로 분할하여 augmentation 적용
3. augmentation 된 데이터셋을 정제
4. 해당 영상의 분할된 데이터셋들의 EAR 측정 및 threshold 값 적용
5. threshold 값을 바탕으로 positive(졸음), negative(정상) 분류
6. cross-validation을 적용한 ML/DL
7. testbed 구축 및 real-time segmentation 작업
8. 최종 test

비록 앞서 말한 타 Github 프로젝트 시스템보다 복잡하고 거추장스럽지만,
실전에 적용하면서 이론 공부도 병행하면 훨씬 효율적이지 않을까 싶으면서 이번 첫 Github 포스팅을 마친다.

다음 포스팅부터는 위의 프로젝트 중 첫번째 단계와 두번째 단계의 과정을 남길 계획이다.
